{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV-nn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xiaorui777/Image-Basic-Operation/blob/master/CV_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6ZQ0R4LfPN7c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sklearn.datasets\n",
        "import sklearn.linear_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZnrMjG2FPkf1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 生成数据集\n",
        "np.random.seed(0)\n",
        "X,y = sklearn.datasets.make_moons(200, noise = 0.2)\n",
        "\n",
        "num_examples = len(X)  # size of training set\n",
        "nn_input_dim = 2\n",
        "nn_output_dim = 2\n",
        "\n",
        "lr = 0.01\n",
        "reg_lambda = 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PeuAWFYIj-UG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def calculate_loss(model):\n",
        "    W1,b1,W2,b2 = model['W1'],model['b1'],model['W2'],model['b2']\n",
        "    z1 = X.dot(W1)+b1\n",
        "    a1 = np.tanh(z1)\n",
        "    \n",
        "    z2 = a1.dot(W2)+b2\n",
        "    \n",
        "    exp_scores = np.exp(z2)\n",
        "    probs = exp_scores/np.sum(exp_scores,axis=1,keepdims=True)\n",
        "    \n",
        "    log_probs = -np.log(probs[range(num_examples),y])\n",
        "    loss = np.sum(log_probs)\n",
        "    \n",
        "    return 1./num_examples * loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9NRU7HslQLz5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_model(nn_hdim, num_passes = 30000, print_loss = False):\n",
        "    W1 = np.random.randn(nn_input_dim, nn_hdim)/np.sqrt(nn_input_dim)\n",
        "    b1 = np.zeros((1, nn_hdim))\n",
        "    W2 = np.random.randn(nn_hdim, nn_output_dim)/np.sqrt(nn_hdim)\n",
        "    b2 = np.zeros((1, nn_output_dim))\n",
        "    \n",
        "    model = {}\n",
        "    \n",
        "    # Gradient descent.\n",
        "    for i in range(0, num_passes):\n",
        "        # forward\n",
        "        z1 = X.dot(W1)+b1\n",
        "        a1 = np.tanh(z1)\n",
        "        z2 = a1.dot(W2)+b2\n",
        "        exp_scores = np.exp(z2)\n",
        "        probs = exp_scores/np.sum(exp_scores, axis = 1, keepdims = True) #softmax\n",
        "        \n",
        "        #bp\n",
        "        delta3 = probs\n",
        "        delta3[range(num_examples), y] -= 1 \n",
        "        dW2 = (a1.T).dot(delta3)\n",
        "        db2 = np.sum(delta3, axis=0, keepdims = True)\n",
        "        delta2 = delta3.dot(W2.T)*(1-np.power(a1,2))  # tanh derivative\n",
        "        dW1 = np.dot(X.T, delta2)\n",
        "        db1 = np.sum(delta2, axis=0)\n",
        "        \n",
        "        # optional\n",
        "        W1 += -lr *dW1\n",
        "        b1  += -lr * db1\n",
        "        W2 += -lr * dW2\n",
        "        b2 += -lr * db2\n",
        "        \n",
        "        model = {'W1':W1,'b1':b1,'W2':W2,'b2':b2}\n",
        "        \n",
        "        if print_loss and i%1000 == 0:\n",
        "            print('Loss after iteration % i:%f'%(i,calculate_loss(model)))\n",
        "    return model\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9mA_wn0YmYS7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "435ef0eb-72be-4374-8965-afd763b65a28"
      },
      "cell_type": "code",
      "source": [
        "# n-dimesional hidden layer\n",
        "model = build_model(10,print_loss = True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss after iteration  0:0.424289\n",
            "Loss after iteration  1000:0.049298\n",
            "Loss after iteration  2000:0.032699\n",
            "Loss after iteration  3000:0.025127\n",
            "Loss after iteration  4000:0.020693\n",
            "Loss after iteration  5000:0.017718\n",
            "Loss after iteration  6000:0.015628\n",
            "Loss after iteration  7000:0.014122\n",
            "Loss after iteration  8000:0.012999\n",
            "Loss after iteration  9000:0.012134\n",
            "Loss after iteration  10000:0.011451\n",
            "Loss after iteration  11000:0.010905\n",
            "Loss after iteration  12000:0.010463\n",
            "Loss after iteration  13000:0.010100\n",
            "Loss after iteration  14000:0.009798\n",
            "Loss after iteration  15000:0.009543\n",
            "Loss after iteration  16000:0.009322\n",
            "Loss after iteration  17000:0.009128\n",
            "Loss after iteration  18000:0.008952\n",
            "Loss after iteration  19000:0.008786\n",
            "Loss after iteration  20000:0.008617\n",
            "Loss after iteration  21000:0.008428\n",
            "Loss after iteration  22000:0.008209\n",
            "Loss after iteration  23000:0.007968\n",
            "Loss after iteration  24000:0.007698\n",
            "Loss after iteration  25000:0.007384\n",
            "Loss after iteration  26000:0.007020\n",
            "Loss after iteration  27000:0.006607\n",
            "Loss after iteration  28000:0.006149\n",
            "Loss after iteration  29000:0.005662\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y4oysTu9kbVw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}